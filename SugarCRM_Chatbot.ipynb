{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm\n",
    "import openai \n",
    "import pinecone\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import html\n",
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "import datetime\n",
    "from time import sleep\n",
    "import os\n",
    "# from _collections_abc import MutableMapping\n",
    "# import collections\n",
    "# collections.Callable = collections.abc.Callable\n",
    "from IPython.display import Markdown\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") \n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://apidocs.sugarcrm.com/schema/10.0.6/ent/sugar.sugar.xml'\n",
    "response = requests.get(url)\n",
    "xml_content = response.content\n",
    "\n",
    "root = ET.fromstring(xml_content)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate through table elements\n",
    "for table in root.findall('.//table'):\n",
    "    table_name = table.get('name')\n",
    "\n",
    "    # Iterate through primaryKey elements and add them to the results\n",
    "    for primary_key in table.findall('.//primaryKey'):\n",
    "        primary_key_column = primary_key.get('column')\n",
    "        results.append({'table': table_name, 'column': primary_key_column, 'key': 'Primary Key', 'linked_table': ''})\n",
    "\n",
    "    # Iterate through column elements\n",
    "    for column in table.findall('.//column'):\n",
    "        column_name = column.get('name')\n",
    "        foreign_key = ''\n",
    "        other_table = ''\n",
    "\n",
    "        # Iterate through child elements\n",
    "        child = column.find('.//child')\n",
    "        if child is not None:\n",
    "            foreign_key = 'Foreign Key'\n",
    "            other_table = child.get('table')\n",
    "\n",
    "        # Iterate through parent elements\n",
    "        parent = column.find('.//parent')\n",
    "        if parent is not None:\n",
    "            foreign_key = 'Foreign Key'\n",
    "            other_table = parent.get('table')\n",
    "\n",
    "        # Add the column to the results only if it's not a primary key\n",
    "        if foreign_key != 'Primary Key':\n",
    "            results.append({'table': table_name, 'column': column_name, 'key': foreign_key, 'linked_table': other_table})\n",
    "\n",
    "# Remove duplicates from results\n",
    "unique_results = []\n",
    "for result in results:\n",
    "    if result not in unique_results:\n",
    "        unique_results.append(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = unique_results\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert the list of dictionaries into a list of strings prior to tokenizing the text\n",
    "\n",
    "def convert_to_text_list(unique_results: List[dict]) -> List[str]:\n",
    "    text_list = []\n",
    "    for entry in unique_results:\n",
    "        text = f\"table:{entry['table']}, column:{entry['column']}, key:{entry['key']}, linked_table:{entry['linked_table']}\"\n",
    "        text_list.append(text)\n",
    "    return text_list\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,  \n",
    "    separators=[\"\\n\"]\n",
    ")\n",
    "\n",
    "text_list = convert_to_text_list(unique_results)  \n",
    "\n",
    "text_string = \"\\n\".join(text_list)\n",
    "\n",
    "chunks = text_splitter.split_text(text_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "index_name = 'sugar-schema-chatbot-ver'\n",
    "\n",
    "\n",
    "pinecone.init(\n",
    "    pinecone_api_key=pinecone_api_key \n",
    "    environment=\"us-east-1-aws\"  \n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='dotproduct'\n",
    "    )\n",
    "\n",
    "index = pinecone.GRPCIndex(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb217133fc9e4fb0a98f58818b49a402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "texts = chunks\n",
    "\n",
    "batch_size = 200  \n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(texts), i + batch_size)\n",
    "    texts_batch = texts[i:i_end]\n",
    "\n",
    "    # create embeddings (try-except added to avoid RateLimitError)\n",
    "    try:\n",
    "        res = openai.Embedding.create(input=texts_batch, engine=embed_model)\n",
    "    except:\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = openai.Embedding.create(input=texts_batch, engine=embed_model)\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "\n",
    "    # Create a list of tuples with index (as a string), embeddings, and metadata (text)\n",
    "    to_upsert = [(str(idx), embed, {\"text\": text}) for idx, embed, text in zip(range(i, i_end), embeds, texts_batch)]\n",
    "\n",
    "\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"drawing on the documentation write me a sql query that joins the accounts, accounts_cstm, user and teams tables, \\\n",
    "only use foreign and primary keys that are linked between tables in the schema\"\n",
    "\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(xq, top_k=10, include_metadata=True)\n",
    "\n",
    "contexts = [item['metadata']['text'] for item in res['matches']]\n",
    "\n",
    "augmented_query = \"\\n\\n---\\n\\n\".join(contexts)+\"\\n\\n-----\\n\\n\"+query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# system message to 'prime' the model\n",
    "\n",
    "primer = f\"\"\"You are Q&A bot with skills in SQL. You are able to answer any question about the SugarCRM database schema.\n",
    "Follow instructions below to answer the user's question.\n",
    "\"\"\"\n",
    "\n",
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": augmented_query}\n",
    "    ]\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided schema and the linked tables you mentioned, you can use the following SQL query to join the accounts, accounts_cstm, users, and teams tables:\n",
       "\n",
       "```sql\n",
       "SELECT a.*, ac.*, u.*, t.*\n",
       "FROM accounts a\n",
       "JOIN accounts_cstm ac ON a.id = ac.id_c\n",
       "JOIN users u ON a.assigned_user_id = u.id\n",
       "JOIN teams t ON a.team_id = t.id;\n",
       "```\n",
       "\n",
       "This query selects all columns from the accounts table (`a.*`), accounts_cstm table (`ac.*`), users table (`u.*`), and teams table (`t.*`). Then it joins these tables using the Foreign Key relations present in the schema:\n",
       "\n",
       "- Join between `accounts` and `accounts_cstm` tables: `a.id = ac.id_c`\n",
       "- Join between `accounts` and `users` tables: `a.assigned_user_id = u.id`\n",
       "- Join between `accounts` and `teams` tables: `a.team_id = t.id`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Display the answer \"\"\"\"\"\n",
    "\n",
    "\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
